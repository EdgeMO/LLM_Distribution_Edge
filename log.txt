llama_perf_sampler_print:    sampling time =      53.79 ms /   132 runs   (    0.41 ms per token,  2453.94 tokens per second)
llama_perf_context_print:        load time = 692.52 ms
llama_perf_context_print: prompt eval time = 24.91 ms / 4 tokens (6.23 ms per token, 160.55 tokens per second)
llama_perf_context_print:        eval time = 1535.79 ms / 127 runs   (12.09 ms per token, 82.69 tokens per second)
llama_perf_context_print:       total time = 1685.87 ms / 131 tokens
llama_perf_sampler_print:    sampling time =      61.80 ms /   132 runs   (    0.47 ms per token,  2135.92 tokens per second)
llama_perf_context_print:        load time = 763.88 ms
llama_perf_context_print: prompt eval time = 26.58 ms / 4 tokens (6.64 ms per token, 150.51 tokens per second)
llama_perf_context_print:        eval time = 1865.22 ms / 127 runs   (14.69 ms per token, 68.09 tokens per second)
llama_perf_context_print:       total time = 2039.29 ms / 131 tokens
llama_perf_sampler_print:    sampling time =      53.09 ms /   132 runs   (    0.40 ms per token,  2486.48 tokens per second)
llama_perf_context_print:        load time = 699.92 ms
llama_perf_context_print: prompt eval time = 26.31 ms / 4 tokens (6.58 ms per token, 152.05 tokens per second)
llama_perf_context_print:        eval time = 1625.45 ms / 127 runs   (12.80 ms per token, 78.13 tokens per second)
llama_perf_context_print:       total time = 1774.49 ms / 131 tokens
llama_perf_sampler_print:    sampling time =      10.40 ms /    19 runs   (    0.55 ms per token,  1827.45 tokens per second)
llama_perf_context_print:        load time = 797.12 ms
llama_perf_context_print: prompt eval time = 30.66 ms / 4 tokens (7.67 ms per token, 130.45 tokens per second)
llama_perf_context_print:        eval time = 239.63 ms / 14 runs   (17.12 ms per token, 58.42 tokens per second)
llama_perf_context_print:       total time = 297.45 ms / 18 tokens
llama_perf_sampler_print:    sampling time =      59.68 ms /   119 runs   (    0.50 ms per token,  1993.97 tokens per second)
llama_perf_context_print:        load time = 810.72 ms
llama_perf_context_print: prompt eval time = 29.22 ms / 4 tokens (7.30 ms per token, 136.90 tokens per second)
llama_perf_context_print:        eval time = 1877.47 ms / 114 runs   (16.47 ms per token, 60.72 tokens per second)
llama_perf_context_print:       total time = 2071.24 ms / 118 tokens
llama_perf_sampler_print:    sampling time =      57.56 ms /   132 runs   (    0.44 ms per token,  2293.34 tokens per second)
llama_perf_context_print:        load time = 768.65 ms
llama_perf_context_print: prompt eval time = 27.87 ms / 4 tokens (6.97 ms per token, 143.53 tokens per second)
llama_perf_context_print:        eval time = 1710.48 ms / 127 runs   (13.47 ms per token, 74.25 tokens per second)
llama_perf_context_print:       total time = 1894.84 ms / 131 tokens
llama_perf_sampler_print:    sampling time =      56.27 ms /   132 runs   (    0.43 ms per token,  2345.71 tokens per second)
llama_perf_context_print:        load time = 696.43 ms
llama_perf_context_print: prompt eval time = 28.54 ms / 4 tokens (7.13 ms per token, 140.17 tokens per second)
llama_perf_context_print:        eval time = 1744.26 ms / 127 runs   (13.73 ms per token, 72.81 tokens per second)
llama_perf_context_print:       total time = 1920.87 ms / 131 tokens
llama_perf_sampler_print:    sampling time =      52.78 ms /   132 runs   (    0.40 ms per token,  2500.95 tokens per second)
llama_perf_context_print:        load time = 691.16 ms
llama_perf_context_print: prompt eval time = 50.11 ms / 4 tokens (12.53 ms per token, 79.83 tokens per second)
llama_perf_context_print:        eval time = 1707.69 ms / 127 runs   (13.45 ms per token, 74.37 tokens per second)
llama_perf_context_print:       total time = 1889.24 ms / 131 tokens
llama_perf_sampler_print:    sampling time =      68.62 ms /   150 runs   (    0.46 ms per token,  2185.79 tokens per second)
llama_perf_context_print:        load time = 801.55 ms
llama_perf_context_print: prompt eval time = 114.68 ms / 22 tokens (5.21 ms per token, 191.84 tokens per second)
llama_perf_context_print:        eval time = 1862.56 ms / 127 runs   (14.67 ms per token, 68.19 tokens per second)
llama_perf_context_print:       total time = 2160.64 ms / 149 tokens
llama_perf_sampler_print:    sampling time =      63.72 ms /   136 runs   (    0.47 ms per token,  2134.27 tokens per second)
llama_perf_context_print:        load time = 762.45 ms
llama_perf_context_print: prompt eval time = 48.51 ms / 8 tokens (6.06 ms per token, 164.92 tokens per second)
llama_perf_context_print:        eval time = 1709.66 ms / 127 runs   (13.46 ms per token, 74.28 tokens per second)
llama_perf_context_print:       total time = 1918.50 ms / 135 tokens
llama_perf_sampler_print:    sampling time =      59.57 ms /   136 runs   (    0.44 ms per token,  2282.88 tokens per second)
llama_perf_context_print:        load time = 768.17 ms
llama_perf_context_print: prompt eval time = 42.63 ms / 8 tokens (5.33 ms per token, 187.65 tokens per second)
llama_perf_context_print:        eval time = 1801.26 ms / 127 runs   (14.18 ms per token, 70.51 tokens per second)
llama_perf_context_print:       total time = 1993.74 ms / 135 tokens
llama_perf_sampler_print:    sampling time =      61.83 ms /   136 runs   (    0.45 ms per token,  2199.58 tokens per second)
llama_perf_context_print:        load time = 786.25 ms
llama_perf_context_print: prompt eval time = 43.12 ms / 8 tokens (5.39 ms per token, 185.51 tokens per second)
llama_perf_context_print:        eval time = 1685.88 ms / 127 runs   (13.27 ms per token, 75.33 tokens per second)
llama_perf_context_print:       total time = 1873.79 ms / 135 tokens
llama_perf_sampler_print:    sampling time =      67.17 ms /   136 runs   (    0.49 ms per token,  2024.62 tokens per second)
llama_perf_context_print:        load time = 825.01 ms
llama_perf_context_print: prompt eval time = 57.03 ms / 8 tokens (7.13 ms per token, 140.27 tokens per second)
llama_perf_context_print:        eval time = 1826.66 ms / 127 runs   (14.38 ms per token, 69.53 tokens per second)
llama_perf_context_print:       total time = 2038.05 ms / 135 tokens
llama_perf_sampler_print:    sampling time =      62.40 ms /   136 runs   (    0.46 ms per token,  2179.56 tokens per second)
llama_perf_context_print:        load time = 645.91 ms
llama_perf_context_print: prompt eval time = 40.10 ms / 8 tokens (5.01 ms per token, 199.52 tokens per second)
llama_perf_context_print:        eval time = 1576.46 ms / 127 runs   (12.41 ms per token, 80.56 tokens per second)
llama_perf_context_print:       total time = 1757.93 ms / 135 tokens
llama_perf_sampler_print:    sampling time =      65.42 ms /   137 runs   (    0.48 ms per token,  2094.16 tokens per second)
llama_perf_context_print:        load time = 773.39 ms
llama_perf_context_print: prompt eval time = 58.03 ms / 9 tokens (6.45 ms per token, 155.08 tokens per second)
llama_perf_context_print:        eval time = 2010.00 ms / 127 runs   (15.83 ms per token, 63.18 tokens per second)
llama_perf_context_print:       total time = 2226.42 ms / 136 tokens
llama_perf_sampler_print:    sampling time =      54.84 ms /   137 runs   (    0.40 ms per token,  2498.27 tokens per second)
llama_perf_context_print:        load time = 647.81 ms
llama_perf_context_print: prompt eval time = 40.71 ms / 9 tokens (4.52 ms per token, 221.05 tokens per second)
llama_perf_context_print:        eval time = 1785.77 ms / 127 runs   (14.06 ms per token, 71.12 tokens per second)
llama_perf_context_print:       total time = 1962.19 ms / 136 tokens
llama_perf_sampler_print:    sampling time =     151.30 ms /   141 runs   (    1.07 ms per token,   931.92 tokens per second)
llama_perf_context_print:        load time = 8668.09 ms
llama_perf_context_print: prompt eval time = 3271.32 ms / 13 tokens (251.64 ms per token, 3.97 tokens per second)
llama_perf_context_print:        eval time = 46373.92 ms / 127 runs   (365.15 ms per token, 2.74 tokens per second)
llama_perf_context_print:       total time = 49964.88 ms / 140 tokens
